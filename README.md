# ğŸš€ AI-Powered PDF Chat Backend (RAG) using FastAPI + GCP + Gemini/OpenAI

A robust, production-ready **Retrieval-Augmented Generation (RAG)** backend built with **FastAPI**, **ChromaDB**, and **Gemini/OpenAI LLMs** â€” deployed on **Google Cloud Platform (GCP)** with secure, programmatic user access.

> âš¡ï¸ 100+ requests/min | ğŸ” User authentication | ğŸ“„ PDF document-based Q&A | â˜ï¸ GCP Persistent Storage | ğŸ§  Embedding with Gemini

---


---

## âœ¨ Features

- âœ… **FastAPI Backend** â€” Lightweight, performant, RESTful API
- ğŸ” **User Authentication** â€” Each user has their own password & access scope
- ğŸ“„ **Per-user PDF Uploads** â€” Isolated document store for each user
- ğŸ” **Document Indexing & Embedding** â€” Uses Gemini embeddings & ChromaDB
- ğŸ¤– **LLM Querying** â€” Contextual Q&A powered by Gemini or OpenAI
- ğŸ’¬ **Parallel Conversations** â€” Supports 30+ users, 100 requests/min tested
- ğŸ“ **Persistent GCP Storage** â€” Stores PDFs, chat history, and embeddings on external disk
- ğŸ§ª **Load Testing** â€” Includes Python-based local simulation for concurrency testing
- ğŸ› ï¸ **Admin Console** â€” Python CLI to manage users & documents securely

---

## ğŸ§  RAG Architecture Overview

1. **User uploads PDF**
2. **PDF is chunked + embedded (Gemini)**
3. **Chunks stored in ChromaDB**
4. **User sends a question**
5. **ChromaDB retrieves relevant context**
6. **Gemini LLM generates response**

---

## ğŸ› ï¸ Tech Stack

| Tool        | Role                         |
|-------------|------------------------------|
| FastAPI     | Backend API Server           |
| ChromaDB    | Vector DB for document search|
| Gemini/OpenAI | Large Language Model (LLM)  |
| PyMuPDF     | PDF text extraction          |
| aiohttp     | Async load testing           |
| GCP VM + Disk | Deployment + Persistent Storage |

---

## ğŸ“‚ Project Structure

FastApi-GCP-Rag/
â”œâ”€â”€ main.py # FastAPI app
â”œâ”€â”€ rag_engine.py # Embedding + LLM logic
â”œâ”€â”€ chroma_client/ # ChromaDB storage
â”œâ”€â”€ users/ # Per-user folders
â”‚ â””â”€â”€ <username>/pdfs/ # User PDFs
â”œâ”€â”€ client.py # Python admin CLI (upload/query/delete)
â”œâ”€â”€ load_test.py # Async load testing script
â”œâ”€â”€ users.json # Local user registry
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### ğŸ”§ 1. GCP VM Setup
- Create a GCP VM (Ubuntu 22+)
- Attach a persistent disk and mount it
- Install dependencies:
```bash
sudo apt update
sudo apt install python3-pip git unzip
pip install -r requirements.txt
```
### ğŸ”‘ 2. Environment Configuration
Create a .env file:
GEMINI_API_KEY=your_gemini_key_here

### ğŸš€ 3. Run FastAPI App

uvicorn main:app --host 0.0.0.0 --port 8000

### ğŸ–¥ï¸ 4.Local Admin Client
Use client.py for managing users & testing PDF queries.

python client.py

Features:

âœ… Create/Delete users

ğŸ“ Upload/List/Delete PDFs

ğŸ’¬ Ask questions on uploaded PDFs

ğŸ“š View user list

ğŸ” Auto-updates users.json based on backend state

### ğŸ§ª Load Testing
Test scalability with:
python load_test.py --users 30 --queries 4 --input users.json
This will simulate:

30 parallel users

4 queries each

100+ requests/minute

### â— Common Errors & Fixes
Error	Fix
models/gemini-pro not found	Ensure you're using correct Gemini model name (e.g., gemini-1.5-pro-002)
users.json not found	Automatically created by client.py or add manually
invalid SSH key format on Windows	Convert PEM to OpenSSH with PuTTYgen or use correct .ppk
ChromaDB folder missing	Ensure path exists and is mounted correctly
